{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "webscraping_redditMAMIA",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gpMKH0S_zra"
      },
      "source": [
        "**Web scraping**\n",
        "reference:\n",
        "https://github.com/a-bergman/Reddit-Post-Classification/blob/master/Code/Data%20Scraping%20%26%20Cleaning.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tStDzRO80h-"
      },
      "source": [
        "# Standard imports\n",
        "import time\n",
        "import pandas             as pd\n",
        "import requests           as re\n",
        "from IPython.core.display import display, HTML"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BICnMeL9ap-"
      },
      "source": [
        "# For r/BabyBumps\n",
        "\n",
        "babybumps_url = \"http://reddit.com/r/BabyBumps.json\"   \n",
        "user_agent  = {\"user-agent\": \"mamia_JHU\"}                        \n",
        "\n",
        "# For r/pregnant\n",
        "\n",
        "pregnant_url = \"http://reddit.com/r/pregnant.json\"\n",
        "\n",
        "# For r/Mommit\n",
        "mommit_url = \"http://reddit.com/r/Mommit.json\"\n",
        "\n",
        "# For r/fitpregnancy\n",
        "\n",
        "fitpreg_url=\"http://reddit.com/r/fitpregnancy.json\"\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOlwN2Ut-OeT",
        "outputId": "634e06c3-df8e-45d8-da2b-5e7f175102a6"
      },
      "source": [
        "# The r/BabyBumps request\n",
        "\n",
        "babybumps_request      = re.get(url     = babybumps_url, \n",
        "                              headers = user_agent)\n",
        "\n",
        "# The r/pregnant request\n",
        "\n",
        "pregnant_request  = re.get(url     = pregnant_url, \n",
        "                              headers = user_agent)\n",
        "# The r/Mommit request\n",
        "\n",
        "mommit_request      = re.get(url     = mommit_url, \n",
        "                              headers = user_agent)\n",
        "\n",
        "# The r/fitpregnancy request\n",
        "\n",
        "fitpreg_request  = re.get(url     = fitpreg_url, \n",
        "                              headers = user_agent)\n",
        "\n",
        "\n",
        "# Printing the status codes\n",
        "\n",
        "print(f\"The r/BabyBumps status code is: {babybumps_request.status_code}\")\n",
        "print(f\"The r/pregnant status code is: {pregnant_request.status_code}\")\n",
        "print(f\"The r/Mommit status code is: {mommit_request.status_code}\")\n",
        "print(f\"The r/fitpregnancy status code is: {fitpreg_request.status_code}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The r/BabyBumps status code is: 200\n",
            "The r/pregnant status code is: 200\n",
            "The r/Mommit status code is: 200\n",
            "The r/fitpregnancy status code is: 200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og-imvAI-9jm",
        "outputId": "1f461c04-cf07-45d3-d52f-4f1a31f33097"
      },
      "source": [
        "# Saving the new r/BabyBumps data\n",
        "\n",
        "bb_data= babybumps_request.json()\n",
        "\n",
        "# Saving the new r/pregnant data\n",
        "\n",
        "preg_data = pregnant_request.json()\n",
        "\n",
        "# Saving the new r/Mommit data\n",
        "\n",
        "mom_data = mommit_request.json()\n",
        "\n",
        "# Saving the r/fitpregnancy data\n",
        "\n",
        "fitpreg_data= fitpreg_request.json()\n",
        "\n",
        "# Checking to make sure we got 25 posts from our first pull\n",
        "\n",
        "print(f'The initial r/BabyBumps request returned    : {len(bb_data[\"data\"][\"children\"])}')\n",
        "print(f'The initial r/pregnant request returned: {len(preg_data[\"data\"][\"children\"])}')\n",
        "print(f'The initial r/Mommit request returned: {len(mom_data[\"data\"][\"children\"])}')\n",
        "print(f'The initial r/fitpregnancy request returned: {len(fitpreg_data[\"data\"][\"children\"])}')\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The initial r/BabyBumps request returned    : 27\n",
            "The initial r/pregnant request returned: 27\n",
            "The initial r/Mommit request returned: 26\n",
            "The initial r/fitpregnancy request returned: 27\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTAgSoRI__WZ",
        "outputId": "3f9f59ee-4c06-46cb-e96d-d03e0e344c79"
      },
      "source": [
        "# Scraping r/BabyBumps\n",
        "\n",
        "# Creating an empty list to save the scraped posts to\n",
        "bb_posts = []\n",
        "\n",
        "# Setting it to `None` for use in the loop\n",
        "after= None\n",
        "\n",
        "for pull in range(40):\n",
        "    \n",
        "    # Tells us the post being scraped in case of errors\n",
        "    print(f\"Pull Attempt {pull + 1}\")\n",
        "    \n",
        "    if after == None:\n",
        "        \n",
        "        # Sets up the initial loop\n",
        "        new_url = babybumps_url\n",
        "        \n",
        "    else:\n",
        "        \n",
        "        # Allows for the creation of the next pull\n",
        "        new_url =babybumps_url + \"?after=\" + after\n",
        "        \n",
        "    # Resetting the request    \n",
        "    request = re.get(url = new_url, headers = user_agent)\n",
        "    \n",
        "    # Only works if the status is good\n",
        "    if request.status_code == 200:\n",
        "        # creates a new dictionary & then appends it to the empty list\n",
        "        bb_data = request.json()\n",
        "        bb_posts.extend(bb_data[\"data\"][\"children\"])\n",
        "        \n",
        "        # Sets a new after value\n",
        "        after = bb_data[\"data\"][\"after\"]\n",
        "        \n",
        "    else:\n",
        "        print(f\"An Error Has Occurred.  Error Code {request.status_code}\")\n",
        "        break\n",
        "        \n",
        "    # Setting a sleep time prevents us from being interpretted as a bot        \n",
        "    time.sleep(2)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pull Attempt 1\n",
            "Pull Attempt 2\n",
            "Pull Attempt 3\n",
            "Pull Attempt 4\n",
            "Pull Attempt 5\n",
            "Pull Attempt 6\n",
            "Pull Attempt 7\n",
            "Pull Attempt 8\n",
            "Pull Attempt 9\n",
            "Pull Attempt 10\n",
            "Pull Attempt 11\n",
            "Pull Attempt 12\n",
            "Pull Attempt 13\n",
            "Pull Attempt 14\n",
            "Pull Attempt 15\n",
            "Pull Attempt 16\n",
            "Pull Attempt 17\n",
            "Pull Attempt 18\n",
            "Pull Attempt 19\n",
            "Pull Attempt 20\n",
            "Pull Attempt 21\n",
            "Pull Attempt 22\n",
            "Pull Attempt 23\n",
            "Pull Attempt 24\n",
            "Pull Attempt 25\n",
            "Pull Attempt 26\n",
            "Pull Attempt 27\n",
            "Pull Attempt 28\n",
            "Pull Attempt 29\n",
            "Pull Attempt 30\n",
            "Pull Attempt 31\n",
            "Pull Attempt 32\n",
            "Pull Attempt 33\n",
            "Pull Attempt 34\n",
            "Pull Attempt 35\n",
            "Pull Attempt 36\n",
            "Pull Attempt 37\n",
            "Pull Attempt 38\n",
            "Pull Attempt 39\n",
            "Pull Attempt 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfZ7qQebB-XX",
        "outputId": "6025ce0a-c47c-4a90-e331-70178c6e30d7"
      },
      "source": [
        "# r/pregnancy\n",
        "preg_posts = []\n",
        "after             = None\n",
        "\n",
        "for pull in range(40):\n",
        "    print(f\"Pull Attempt {pull + 1}\")\n",
        "    if after == None:    \n",
        "        new_url = pregnant_url\n",
        "    else:\n",
        "        new_url = pregnant_url + \"?after=\" + after\n",
        "    pregnancy_request = re.get(url = new_url, headers = user_agent)\n",
        "    if pregnancy_request.status_code == 200:\n",
        "        preg_data = pregnancy_request.json()\n",
        "        preg_posts.extend(preg_data[\"data\"][\"children\"])\n",
        "        after = preg_data[\"data\"][\"after\"]\n",
        "    else:\n",
        "        print(f\"An Error Has Occurred.  Error Code {pregnancy_request.status_code}\")\n",
        "        break\n",
        "    time.sleep(2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pull Attempt 1\n",
            "Pull Attempt 2\n",
            "Pull Attempt 3\n",
            "Pull Attempt 4\n",
            "Pull Attempt 5\n",
            "Pull Attempt 6\n",
            "Pull Attempt 7\n",
            "Pull Attempt 8\n",
            "Pull Attempt 9\n",
            "Pull Attempt 10\n",
            "Pull Attempt 11\n",
            "Pull Attempt 12\n",
            "Pull Attempt 13\n",
            "Pull Attempt 14\n",
            "Pull Attempt 15\n",
            "Pull Attempt 16\n",
            "Pull Attempt 17\n",
            "Pull Attempt 18\n",
            "Pull Attempt 19\n",
            "Pull Attempt 20\n",
            "Pull Attempt 21\n",
            "Pull Attempt 22\n",
            "Pull Attempt 23\n",
            "Pull Attempt 24\n",
            "Pull Attempt 25\n",
            "Pull Attempt 26\n",
            "Pull Attempt 27\n",
            "Pull Attempt 28\n",
            "Pull Attempt 29\n",
            "Pull Attempt 30\n",
            "Pull Attempt 31\n",
            "Pull Attempt 32\n",
            "Pull Attempt 33\n",
            "Pull Attempt 34\n",
            "Pull Attempt 35\n",
            "Pull Attempt 36\n",
            "Pull Attempt 37\n",
            "Pull Attempt 38\n",
            "Pull Attempt 39\n",
            "Pull Attempt 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEjhza-7CljN",
        "outputId": "850230ff-4bc6-4bf7-ca3e-a09d56a8328d"
      },
      "source": [
        "# r/Mommit\n",
        "mommit_posts = []\n",
        "after             = None\n",
        "\n",
        "for pull in range(40):\n",
        "    print(f\"Pull Attempt {pull + 1}\")\n",
        "    if after == None:    \n",
        "        new_url = mommit_url\n",
        "    else:\n",
        "        new_url = mommit_url + \"?after=\" + after\n",
        "    mommit_request = re.get(url = new_url, headers = user_agent)\n",
        "    if mommit_request.status_code == 200:\n",
        "        mom_data = mommit_request.json()\n",
        "        mommit_posts.extend(mom_data[\"data\"][\"children\"])\n",
        "        after = mom_data[\"data\"][\"after\"]\n",
        "    else:\n",
        "        print(f\"An Error Has Occurred.  Error Code {mommit_request.status_code}\")\n",
        "        break\n",
        "    time.sleep(2)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pull Attempt 1\n",
            "Pull Attempt 2\n",
            "Pull Attempt 3\n",
            "Pull Attempt 4\n",
            "Pull Attempt 5\n",
            "Pull Attempt 6\n",
            "Pull Attempt 7\n",
            "Pull Attempt 8\n",
            "Pull Attempt 9\n",
            "Pull Attempt 10\n",
            "Pull Attempt 11\n",
            "Pull Attempt 12\n",
            "Pull Attempt 13\n",
            "Pull Attempt 14\n",
            "Pull Attempt 15\n",
            "Pull Attempt 16\n",
            "Pull Attempt 17\n",
            "Pull Attempt 18\n",
            "Pull Attempt 19\n",
            "Pull Attempt 20\n",
            "Pull Attempt 21\n",
            "Pull Attempt 22\n",
            "Pull Attempt 23\n",
            "Pull Attempt 24\n",
            "Pull Attempt 25\n",
            "Pull Attempt 26\n",
            "Pull Attempt 27\n",
            "Pull Attempt 28\n",
            "Pull Attempt 29\n",
            "Pull Attempt 30\n",
            "Pull Attempt 31\n",
            "Pull Attempt 32\n",
            "Pull Attempt 33\n",
            "Pull Attempt 34\n",
            "Pull Attempt 35\n",
            "Pull Attempt 36\n",
            "Pull Attempt 37\n",
            "Pull Attempt 38\n",
            "Pull Attempt 39\n",
            "Pull Attempt 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IR5l2JQC2yx",
        "outputId": "b9557a99-88f9-4d0d-cfc9-955c1df7c045"
      },
      "source": [
        "# r/fitpregnancy\n",
        "fitpreg_posts = []\n",
        "after             = None\n",
        "\n",
        "for pull in range(40):\n",
        "    print(f\"Pull Attempt {pull + 1}\")\n",
        "    if after == None:    \n",
        "        new_url = fitpreg_url\n",
        "    else:\n",
        "        new_url = fitpreg_url + \"?after=\" + after\n",
        "    fitpreg_request = re.get(url = new_url, headers = user_agent)\n",
        "    if fitpreg_request.status_code == 200:\n",
        "        fitpreg_data = fitpreg_request.json()\n",
        "        fitpreg_posts.extend(fitpreg_data[\"data\"][\"children\"])\n",
        "        after = fitpreg_data[\"data\"][\"after\"]\n",
        "    else:\n",
        "        print(f\"An Error Has Occurred.  Error Code {fitpreg_request.status_code}\")\n",
        "        break\n",
        "    time.sleep(2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pull Attempt 1\n",
            "Pull Attempt 2\n",
            "Pull Attempt 3\n",
            "Pull Attempt 4\n",
            "Pull Attempt 5\n",
            "Pull Attempt 6\n",
            "Pull Attempt 7\n",
            "Pull Attempt 8\n",
            "Pull Attempt 9\n",
            "Pull Attempt 10\n",
            "Pull Attempt 11\n",
            "Pull Attempt 12\n",
            "Pull Attempt 13\n",
            "Pull Attempt 14\n",
            "Pull Attempt 15\n",
            "Pull Attempt 16\n",
            "Pull Attempt 17\n",
            "Pull Attempt 18\n",
            "Pull Attempt 19\n",
            "Pull Attempt 20\n",
            "Pull Attempt 21\n",
            "Pull Attempt 22\n",
            "Pull Attempt 23\n",
            "Pull Attempt 24\n",
            "Pull Attempt 25\n",
            "Pull Attempt 26\n",
            "Pull Attempt 27\n",
            "Pull Attempt 28\n",
            "Pull Attempt 29\n",
            "Pull Attempt 30\n",
            "Pull Attempt 31\n",
            "Pull Attempt 32\n",
            "Pull Attempt 33\n",
            "Pull Attempt 34\n",
            "Pull Attempt 35\n",
            "Pull Attempt 36\n",
            "Pull Attempt 37\n",
            "Pull Attempt 38\n",
            "Pull Attempt 39\n",
            "Pull Attempt 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5Xu7bxVFNR-"
      },
      "source": [
        "bb=pd.DataFrame(bb_posts)\n",
        "preg=pd.DataFrame(preg_posts)\n",
        "mom=pd.DataFrame(mommit_posts)\n",
        "fitpreg=pd.DataFrame(fitpreg_posts)\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWNE6r5WFxjH"
      },
      "source": [
        "# Using list comprehension to extract the values we want from each post\n",
        "\n",
        "bb_id    = [bb['data'][post]['id'] for post in range(len(bb['data']))]\n",
        "bb_auth  = [bb['data'][post]['author'] for post in range(len(bb['data']))]\n",
        "bb_title = [bb['data'][post]['title'] for post in range(len(bb['data']))]\n",
        "bb_self  = [bb['data'][post]['selftext'] for post in range(len(bb['data']))]\n",
        "bb_comment=[bb['data'][post]['num_comments'] for post in range(len(bb['data']))]\n",
        "\n",
        "# Creating new columns and setting them equal to the list comprehension results\n",
        "\n",
        "bb[\"id\"]       = bb_id\n",
        "bb[\"title\"]    = bb_title\n",
        "bb[\"selftext\"] = bb_self\n",
        "bb[\"author\"]   = bb_auth\n",
        "bb[\"source\"]   = \"bb\"\n",
        "bb[\"comment_count\"]= bb_comment\n",
        "\n",
        "# Using list comprehension to extract the values we want from each post\n",
        "\n",
        "preg_id    = [preg['data'][post]['id'] for post in range(len(preg['data']))]\n",
        "preg_auth  = [preg['data'][post]['author'] for post in range(len(preg['data']))]\n",
        "preg_title = [preg['data'][post]['title'] for post in range(len(preg['data']))]\n",
        "preg_self  = [preg['data'][post]['selftext'] for post in range(len(preg['data']))]\n",
        "preg_comment=[preg['data'][post]['num_comments'] for post in range(len(preg['data']))]\n",
        "\n",
        "# Creating new columns and setting them equal to the list comprehension results\n",
        "\n",
        "preg[\"id\"]       = preg_id\n",
        "preg[\"title\"]    = preg_title\n",
        "preg[\"selftext\"] = preg_self\n",
        "preg[\"author\"]   = preg_auth\n",
        "preg[\"source\"]   = \"preg\"\n",
        "preg[\"comment_count\"]= preg_comment\n",
        "\n",
        "# Using list comprehension to extract the values we want from each post\n",
        "\n",
        "mom_id    = [mom['data'][post]['id'] for post in range(len(mom['data']))]\n",
        "mom_auth  = [mom['data'][post]['author'] for post in range(len(mom['data']))]\n",
        "mom_title = [mom['data'][post]['title'] for post in range(len(mom['data']))]\n",
        "mom_self  = [mom['data'][post]['selftext'] for post in range(len(mom['data']))]\n",
        "mom_comment=[mom['data'][post]['num_comments'] for post in range(len(mom['data']))]\n",
        "\n",
        "# Creating new columns and setting them equal to the list comprehension results\n",
        "\n",
        "mom[\"id\"]       = mom_id\n",
        "mom[\"title\"]    = mom_title\n",
        "mom[\"selftext\"] = mom_self\n",
        "mom[\"author\"]   = mom_auth\n",
        "mom[\"source\"]   = \"mom\"\n",
        "mom[\"comment_count\"]= mom_comment\n",
        "\n",
        "# Using list comprehension to extract the values we want from each post\n",
        "\n",
        "fitpreg_id    = [fitpreg['data'][post]['id'] for post in range(len(fitpreg['data']))]\n",
        "fitpreg_auth  = [fitpreg['data'][post]['author'] for post in range(len(fitpreg['data']))]\n",
        "fitpreg_title = [fitpreg['data'][post]['title'] for post in range(len(fitpreg['data']))]\n",
        "fitpreg_self  = [fitpreg['data'][post]['selftext'] for post in range(len(fitpreg['data']))]\n",
        "fitpreg_comment=[fitpreg['data'][post]['num_comments'] for post in range(len(fitpreg['data']))]\n",
        "\n",
        "# Creating new columns and setting them equal to the list comprehension results\n",
        "\n",
        "fitpreg[\"id\"]       = fitpreg_id\n",
        "fitpreg[\"title\"]    = fitpreg_title\n",
        "fitpreg[\"selftext\"] = fitpreg_self\n",
        "fitpreg[\"author\"]   = fitpreg_auth\n",
        "fitpreg[\"source\"]   = \"fitpreg\"\n",
        "fitpreg[\"comment_count\"]= fitpreg_comment"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-B1wffpHxPJ"
      },
      "source": [
        "# Dropping posts by Automoderator, dropping stickied posts\n",
        "bb = bb[bb.author != 'AutoModerator']\n",
        "mom = mom[mom.author != 'AutoModerator']\n",
        "preg = preg[preg.author != 'AutoModerator']\n",
        "fitpreg = fitpreg[fitpreg.author != 'AutoModerator']"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDGr3ZfZORld",
        "outputId": "2d737bad-f771-41f4-bccd-644e4f0545f1"
      },
      "source": [
        "combined_data = pd.concat(objs = [bb,mom,preg,fitpreg],axis = 0,sort = False)\n",
        "# Concatenating the two columns with a space\n",
        "\n",
        "combined_data[\"text\"] = combined_data[\"title\"] + \" \" + combined_data[\"selftext\"]\n",
        "\n",
        "# Using a regular expression to remove any remaining non-letters\n",
        "\n",
        "combined_data[\"text\"] = combined_data[\"text\"].str.replace(\"[^a-zA-Z ]\", \"\")\n",
        "\n",
        "combined_data.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3819, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2OK49VPOhI8",
        "outputId": "7f0ca3cb-a05c-4866-90c2-d2e1510ccbd5"
      },
      "source": [
        "# Dropping the nulls in place\n",
        "\n",
        "combined_data.dropna(inplace = True)\n",
        "\n",
        "# Checking the length of the dataframe\n",
        "\n",
        "print(f\"After dropping nulls, the dataframe now has {combined_data.shape[0]} rows.\")\n",
        "\n",
        "# Dropping the duplicates in place\n",
        "\n",
        "combined_data.drop_duplicates(\"id\",\n",
        "                              keep    = \"first\",\n",
        "                              inplace = True)\n",
        "\n",
        "# Checking the length of the dataframe\n",
        "\n",
        "print(f\"After dropping duplicate ids, the dataframe now has {combined_data.shape[0]} rows.\")\n",
        "\n",
        "# Dropping selftext and title and unnecessary columns\n",
        "combined_data=combined_data.drop([\"data\", \"kind\",\"selftext\",\"title\"], axis= 1)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After dropping nulls, the dataframe now has 3819 rows.\n",
            "After dropping duplicate ids, the dataframe now has 3794 rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "O6EOkQT0Qg02",
        "outputId": "240479e1-acae-4e20-fd48-2e90b9ac8eb8"
      },
      "source": [
        "from google.colab import files\n",
        "combined_data.to_csv('webscrape_MAMIA.csv') \n",
        "files.download('webscrape_MAMIA.csv')\n"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_2ce626d2-a427-4542-9224-b6d7d5c919f8\", \"webscrape_MAMIA.csv\", 2893131)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}